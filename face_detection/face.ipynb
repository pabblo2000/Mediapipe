{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Puntos de referencia faciales](https://omes-va.com/wp-content/uploads/2021/06/detector_rostro_medipipe_6puntos.jpeg)<br><u>**Crédito:** [Gabriela Solano](https://omes-va.com/deteccion-de-rostros-mediapipe-python/)</u>\n",
    "\n",
    "## **<u>Puntos de referencia faciales</u>**\n",
    "\n",
    "**0. RIGHT_EYE** - Ojo derecho<br>\n",
    "**1. LEFT_EYE** - Ojo izquierdo<br>\n",
    "**2. NOSE_TIP** - Punta de la nariz<br>\n",
    "**3. MOUTH_CENTER** - Centro de la boca<br>\n",
    "**4. RIGHT_EAR_TRAGION** - Trago del oído derecho<br>\n",
    "**5. LEFT_EAR_TRAGION** - Trago del oído izquierdo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODO FOTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import mediapipe as mp \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Definimos el modulo de deteccion de rostros, el modulo de dibujo y los estilos de dibujo\n",
    "mp_face = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# --------------- Configuración --------------- #\n",
    "# Establecemos el path de la imagen\n",
    "img = \"face1.jpg\"\n",
    "path = \"img/\" + img \n",
    "index = [0, 1]\n",
    "\n",
    "with mp_face.FaceDetection(\n",
    "    min_detection_confidence=0.5, #Confianza mínima para detectar (Default: 0.5)\n",
    "    )as face:\n",
    "\n",
    "    # Cargamos la imagen\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    # Guardamos el alto y ancho de la imagen\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # ------------------ Conversión de la imagen ------------------ #\n",
    "    # Convertimos la imagen a RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # ------------------ Dibujamos e imprimimos los puntos ------------------ #\n",
    "    results = face.process(image_rgb) # Procesamos la imagen\n",
    "    print(\"Detections: \", results.detections) #Imprimimos las detecciones   \n",
    "\n",
    "    # --------------- Personalización --------------- #\n",
    "    # Personalizar cómo se dibujan los landmarks (puntos)\n",
    "    custom_landmark_style = mp.solutions.drawing_utils.DrawingSpec(\n",
    "    color=(0, 0, 255), # Rojo\n",
    "    thickness=5,        \n",
    "    circle_radius=3     \n",
    "    )\n",
    "\n",
    "    # Personalizar cómo se dibujan las conexiones o contornos\n",
    "    custom_connection_style = mp.solutions.drawing_utils.DrawingSpec(\n",
    "    color=(0, 255, 0), # Verde\n",
    "    thickness=3\n",
    "    )\n",
    "    \n",
    "    if results.detections: # Verificamos si hay detecciones\n",
    "\n",
    "        \"\"\"Modo automatico(No te permite elegir):\"\"\"\n",
    "        for detection in results.detections:\n",
    "            mp_drawing.draw_detection(\n",
    "                image, \n",
    "                detection,\n",
    "                custom_landmark_style,\n",
    "                custom_connection_style\n",
    "            )\n",
    "               \n",
    "\n",
    "        \"\"\"Modo manual(Te permite elegir que puntos y configuracion):\"\"\"\n",
    "        # for detection in results.detections:\n",
    "        #     # Bounding Box\n",
    "        #     xmin = int(detection.location_data.relative_bounding_box.xmin * width)\n",
    "        #     ymin = int(detection.location_data.relative_bounding_box.ymin * height)\n",
    "        #     w = int(detection.location_data.relative_bounding_box.width * width)\n",
    "        #     h = int(detection.location_data.relative_bounding_box.height * height)\n",
    "        #     cv2.rectangle(img = image, pt1 = (xmin, ymin), pt2 =(xmin+w, ymin+h), color = (0, 255, 255), thickness=2) # Dibujamos el cuadro (amarillo)\n",
    "\n",
    "        #     # Ojo derecho\n",
    "        #     x_RE = int(detection.location_data.relative_keypoints[0].x * width)\n",
    "        #     y_RE = int(detection.location_data.relative_keypoints[0].y * height)\n",
    "        #     cv2.circle(img = image, center = (x_RE, y_RE), radius =3, color = (0, 0, 255), thickness=3) # Dibujamos el ojo derecho (azul)\n",
    "\n",
    "        #     # Ojo izquierdo\n",
    "        #     x_LE = int(detection.location_data.relative_keypoints[1].x * width)\n",
    "        #     y_LE = int(detection.location_data.relative_keypoints[1].y * height)\n",
    "        #     cv2.circle(img = image, center = (x_LE, y_LE), radius =3, color = (0, 0, 255), thickness=3) # Dibujamos el ojo izquierdo (azul)\n",
    "\n",
    "        #     # Punta de la Nariz\n",
    "        #     x_N = int(detection.location_data.relative_keypoints[2].x * width)\n",
    "        #     y_N = int(detection.location_data.relative_keypoints[2].y * height)\n",
    "        #     cv2.circle(img = image, center = (x_N, y_N), radius =3, color = (0, 255, 0), thickness=3) # Dibujamos la nariz (verde)\n",
    "\n",
    "        #     # Centro de la Boca\n",
    "        #     x_M = int(detection.location_data.relative_keypoints[3].x * width)\n",
    "        #     y_M = int(detection.location_data.relative_keypoints[3].y * height)\n",
    "        #     cv2.circle(img = image, center = (x_M, y_M), radius =3, color = (255, 0, 255), thickness=3) # Dibujamos la boca (purpura)\n",
    "\n",
    "        #     # Trago de la Oreja derecha\n",
    "        #     x_RE = int(detection.location_data.relative_keypoints[4].x * width)\n",
    "        #     y_RE = int(detection.location_data.relative_keypoints[4].y * height)\n",
    "        #     cv2.circle(img = image, center = (x_RE, y_RE), radius =3, color = (255, 0, 0), thickness=3) # Dibujamos la oreja derecha (roja)\n",
    "\n",
    "        #     # Trago de la Oreja izquierda\n",
    "        #     x_LE = int(detection.location_data.relative_keypoints[5].x * width)\n",
    "        #     y_LE = int(detection.location_data.relative_keypoints[5].y * height)\n",
    "        #     cv2.circle(img = image, center = (x_LE, y_LE), radius =3, color = (255, 0, 0), thickness=3) # Dibujamos la oreja izquierda (roja)\n",
    "\n",
    "        \"\"\"Modo manual(Te permite elegir que puntos de una lista:\"\"\"\n",
    "        # for detection in results.detections:\n",
    "        #     for i in index:\n",
    "        #         x = int(detection.location_data.relative_keypoints[i].x * width)\n",
    "        #         y = int(detection.location_data.relative_keypoints[i].y * height)\n",
    "        #         cv2.circle(img = image, center = (x, y), radius =3, color = (0, 0, 255), thickness=3) # Dibujamos los puntos (rojo)\n",
    "\n",
    "cv2.imshow(\"Image\", image) # Mostramos la imagen\n",
    "\n",
    "# --------------- Bucle para cerrar las ventanas --------------- #\n",
    "\"\"\"Metodo de seleccion de tecla\"\"\"\n",
    "while True:\n",
    "    key = cv2.waitKey(0) & 0xFF # Capturamos la tecla que presionamos\n",
    "    if key == 27: # Si presionamos la tecla 'ESC' cerramos todas las ventanas\n",
    "        break\n",
    "\n",
    "\"\"\"Metodo de cierre con cualquier tecla\"\"\"\n",
    "# cv2.waitKey(0) # Esperamos a que presionemos una tecla\n",
    "\n",
    "cv2.destroyAllWindows() # Cerramos todas las ventanas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODO VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import mediapipe as mp \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Definimos el modulo de Mediapipe Face Detection, el modulo de dibujo y los estilos de dibujo\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles # Estilos de dibujo predeterminados\n",
    "\n",
    "# Inicializamos la camara\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "# --------------- Configuración --------------- #\n",
    "index = [0, 1] # Indices de los puntos a dibujar\n",
    "with mp_face_detection.FaceDetection(\n",
    "    min_detection_confidence=0.5, #Confianza mínima para detectar (Default: 0.5)\n",
    "    ) as face_detection:\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read() # Capturamos el frame de la camara\n",
    "        if ret == False:\n",
    "            break\n",
    "\n",
    "        # Guardamos el alto y ancho del frame\n",
    "        height, width, _ = frame.shape\n",
    "\n",
    "        # Volteamos el frame\n",
    "        frame = cv2.flip(frame, 1) \n",
    "        \n",
    "        # Convertimos el frame a RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # ------------------ Dibujamos e imprimimos las lineas y puntos ------------------ #\n",
    "        results = face_detection.process(frame_rgb) # Procesamos el frame\n",
    "        print(results.detections) # Imprimimos las detecciones\n",
    "\n",
    "        # --------------- Personalización --------------- #\n",
    "        # Personalizar cómo se dibujan los landmarks (puntos)\n",
    "        custom_landmark_style = mp.solutions.drawing_utils.DrawingSpec(\n",
    "        color=(0, 0, 255), # Rojo\n",
    "        thickness=5,        \n",
    "        circle_radius=3     \n",
    "        )\n",
    "\n",
    "        # Personalizar cómo se dibujan las conexiones o contornos\n",
    "        custom_connection_style = mp.solutions.drawing_utils.DrawingSpec(\n",
    "        color=(0, 255, 0), # Verde\n",
    "        thickness=3\n",
    "        )\n",
    "\n",
    "        if results.detections: # Verificamos si hay detecciones\n",
    "\n",
    "            \"\"\"Modo automatico(No te permite elegir):\"\"\"\n",
    "            for detection in results.detections:\n",
    "                mp_drawing.draw_detection(\n",
    "                    frame,\n",
    "                    detection,\n",
    "                    custom_landmark_style,\n",
    "                    custom_connection_style\n",
    "                )\n",
    "\n",
    "            \"\"\"Modo manual(Te permite elegir que puntos):\"\"\"\n",
    "            # for detection in results.detections: \n",
    "            #     if index:\n",
    "            #         for i in index:\n",
    "            #             x = int(detection.location_data.relative_keypoints[i].x * width)\n",
    "            #             y = int(detection.location_data.relative_keypoints[i].y * height)\n",
    "            #             cv2.circle(frame, (x, y), 3, (0, 0, 255), 3) # Dibujamos los puntos (rojo)\n",
    "\n",
    "        cv2.imshow(\"Frame\", frame) # Mostramos el frame\n",
    "\n",
    "        # --------------- Bucle para cerrar la ventana --------------- #\n",
    "        \"\"\"Metodo de seleccion de tecla\"\"\"\n",
    "        # k = cv2.waitKey(1) & 0xFF # Capturamos la tecla que presionamos y acortamos los bits a 8 para que no haya problemas de compatibilidad\n",
    "        # if k == 27: # Si presionamos la tecla 'ESC' (27) cerramos la ventana (se puede tambien poner ord('q'))\n",
    "        #     break\n",
    "\n",
    "        \"\"\"Metodo de cierre con cualquier tecla\"\"\"\n",
    "        key = cv2.waitKey(1) # Esperamos a que presionemos una tecla\n",
    "        # Si key es diferente de -1 quiere decir que se presiono una tecla\n",
    "        if key != -1:\n",
    "            break\n",
    "\n",
    "cap.release() # Liberamos la camara\n",
    "cv2.destroyAllWindows()  # Cerramos todas las ventanas\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
